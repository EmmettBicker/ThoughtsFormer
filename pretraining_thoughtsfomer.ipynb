{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length >\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "output\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "output\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from thoughtsformer import ThoughtsFormer\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = ThoughtsFormer.from_pretrained_GPT2()\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def generate(prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward_ppo_with_tokens(input_ids, torch.zeros_like(input_ids),0)[0][:,-1,:]\n",
    "            \n",
    "        next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
    "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "        print(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "        \n",
    "generate(\"next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.disable_thought_encoding:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1933ceeca70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.load(\"test.pt\", weights_only=True)\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "from one_step_thoughtsformer import ThoughtsFormer, NewGELUActivation\n",
    "# t = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "pret = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "custom_model = ThoughtsFormer(num_layers=12,vocab_size=50257, d_embed = 768, dim_feedforward=768 * 4, n_head=12, max_context_length=1024, max_thought_len=0, dropout=0.15, activation=NewGELUActivation(), sinusoidal_position_encoding=False)\n",
    "\n",
    "\n",
    "pdict = pret.state_dict()\n",
    "cdict = custom_model.state_dict()\n",
    "# sentence = \"Once upon a time\"\n",
    "pdict = pret.state_dict()\n",
    "cdict = custom_model.state_dict()\n",
    "\n",
    "explicit_map = {\n",
    "    'token_embedding.weight' : 'transformer.wte.weight',\n",
    "    'policy_feedforward.weight' : 'lm_head.weight',\n",
    "    'transformer.transformer.norm.weight' : 'transformer.ln_f.weight',\n",
    "    'transformer.transformer.norm.bias' : 'transformer.ln_f.bias',\n",
    "    'transformer.dual_positional_encoding.learned_positional_encoding.weight' : 'transformer.wpe.weight'\n",
    "}\n",
    "\n",
    "for k, v in explicit_map.items():\n",
    "    assert cdict[k].shape == pdict[v].shape\n",
    "    cdict[k].copy_(pdict[v])\n",
    "    \n",
    "for i in range(12):\n",
    "    layer_explicit_map = {\n",
    "        f\"transformer.transformer.layers.{i}.linear1.weight\" : f\"transformer.h.{i}.mlp.c_fc.weight\" ,\n",
    "        f\"transformer.transformer.layers.{i}.linear1.bias\" : f\"transformer.h.{i}.mlp.c_fc.bias\" ,\n",
    "        f\"transformer.transformer.layers.{i}.linear2.weight\" : f\"transformer.h.{i}.mlp.c_proj.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.linear2.bias\" : f\"transformer.h.{i}.mlp.c_proj.bias\" ,\n",
    "        f\"transformer.transformer.layers.{i}.norm1.weight\" : f\"transformer.h.{i}.ln_1.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.norm1.bias\" : f\"transformer.h.{i}.ln_1.bias\", \n",
    "        f\"transformer.transformer.layers.{i}.norm2.weight\" : f\"transformer.h.{i}.ln_2.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.norm2.bias\" : f\"transformer.h.{i}.ln_2.bias\", \n",
    "        f\"transformer.transformer.layers.{i}.self_attn.out_proj.weight\" : f\"transformer.h.{i}.attn.c_proj.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.self_attn.out_proj.bias\" : f\"transformer.h.{i}.attn.c_proj.bias\",\n",
    "        f\"transformer.transformer.layers.{i}.self_attn.in_proj_weight\":  f\"transformer.h.{i}.attn.c_attn.weight\",\n",
    "        f\"transformer.transformer.layers.{i}.self_attn.in_proj_bias\" : f\"transformer.h.{i}.attn.c_attn.bias\"\n",
    "    }\n",
    "    \n",
    "    transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "    for k, v in layer_explicit_map.items():\n",
    "        \n",
    "        if any(v.endswith(w) for w in transposed):\n",
    "            assert pdict[v].shape[::-1] == cdict[k].shape\n",
    "            with torch.no_grad():\n",
    "                cdict[k].copy_(pdict[v].t())\n",
    "        else:\n",
    "            # print(cdict[k].shape, pdict[v].shape, k, v)\n",
    "            with torch.no_grad():\n",
    "                assert cdict[k].shape == pdict[v].shape\n",
    "                cdict[k].copy_(pdict[v])\n",
    "    \n",
    "custom_model.load_state_dict(cdict)\n",
    "# cdict['token_embedding.weight'].shape\n",
    "# cdict['transformer.transformer.layers.0.linear2.weight'].shape\n",
    "\n",
    "sentence = \"once upon a time\"\n",
    "\n",
    "\n",
    "from bpe import BPETokenizer\n",
    "tokenizer = BPETokenizer()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# with torch.no_grad():\n",
    "#     tokens = torch.tensor(tokenizer(sentence)).view(1,-1)\n",
    "#     custom_model.eval()\n",
    "#     predictions = custom_model.forward_ppo_with_tokens(tokens, torch.zeros_like(tokens),0)[0]\n",
    "  \n",
    "#     print(custom_model.transformer.transformer.layers[0](input))\n",
    "    \n",
    "    \n",
    "#     print(custom_model.transformer.transformer.layers[0](input))\n",
    "\n",
    "# x = predictions.argmax(dim=-1)\n",
    "# tokenizer.decode(x[0])\n",
    "# print(\"\\n\\nDesired Output\")\n",
    "# print(pret(tokens,output_hidden_states=True).hidden_states[1])\n",
    "\n",
    "\n",
    "# Desired Output\n",
    "# tensor([[[ 0.3191,  0.6466,  1.1327,  ..., -0.0743,  0.7379, -0.3372],\n",
    "#          [-0.3657, -0.3845, -0.2498,  ..., -0.0071,  0.2876,  0.2585],\n",
    "#          [-1.4182,  0.1991, -0.4063,  ...,  0.0237,  0.1473, -0.4916],\n",
    "#          [ 0.2380, -0.8441, -0.0074,  ...,  0.6175, -0.6014,  0.4939]]],\n",
    "#        grad_fn=<AddBackward0>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "print(\"hi\")\n",
    "print(\"hi\")\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired Output\n",
    "# tensor([[[ 0.3191,  0.6466,  1.1327,  ..., -0.0743,  0.7379, -0.3372],\n",
    "#          [-0.3657, -0.3845, -0.2498,  ..., -0.0071,  0.2876,  0.2585],\n",
    "#          [-1.4182,  0.1991, -0.4063,  ...,  0.0237,  0.1473, -0.4916],\n",
    "#          [ 0.2380, -0.8441, -0.0074,  ...,  0.6175, -0.6014,  0.4939]]],\n",
    "#        grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.2619, -0.7038,  1.1560,  ..., -0.7938,  0.8593, -1.1736],\n",
       "          [ 0.7986, -1.2712,  0.3632,  ...,  0.3620,  1.5317, -2.4150],\n",
       "          [ 2.6520,  2.7002, -1.5714,  ..., -0.5710,  0.2848, -1.4666],\n",
       "          ...,\n",
       "          [ 0.2420,  0.1363, -0.1294,  ..., -0.8941, -1.0109, -0.3575],\n",
       "          [ 0.2408,  0.1860, -0.1360,  ..., -0.8679, -1.0096, -0.3522],\n",
       "          [ 0.0075, -0.0149, -0.1759,  ..., -0.5826, -0.4573, -0.2208]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Block\n",
    "desired_layer: GPT2Block = pret.transformer.h[0].to(\"cpu\")\n",
    "print(input.shape)\n",
    "desired_layer.forward(input.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2614, -0.7036,  1.1556,  ..., -0.7940,  0.8593, -1.1735],\n",
       "         [ 0.7983, -1.2712,  0.3622,  ...,  0.3625,  1.5325, -2.4162],\n",
       "         [ 2.6506,  2.7003, -1.5726,  ..., -0.5697,  0.2851, -1.4677],\n",
       "         ...,\n",
       "         [ 0.2421,  0.1367, -0.1292,  ..., -0.8943, -1.0112, -0.3574],\n",
       "         [ 0.2412,  0.1864, -0.1357,  ..., -0.8680, -1.0098, -0.3523],\n",
       "         [-0.2108,  0.1408, -0.1659,  ..., -0.6663, -0.4568, -0.2405]]],\n",
       "       grad_fn=<WhereBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "encoder_layer: nn.TransformerEncoderLayer = custom_model.transformer.transformer.layers[0]\n",
    "mask = torch.zeros_like(input[:,:,0]).bool()\n",
    "encoder_layer.eval()\n",
    "encoder_layer.forward(input.to(\"cpu\"), src_mask=mask, is_causal=True)\n",
    "\n",
    "# import torch.nn as nn\n",
    "# encoder_layer: nn.TransformerEncoderLayer = custom_model.transformer.transformer.layers[0]\n",
    "# mask = torch.zeros_like(input[:,:,0]).bool()\n",
    "# mask[0,-1] = True\n",
    "# mask[0,-2] = True\n",
    "# mask[0,-3] = True\n",
    "\n",
    "# after:  tensor([[[ 0.0275,  0.0141, -0.0031,  ...,  0.5349,  0.2867,  0.1896],\n",
    "#          [ 0.0340,  0.1176,  0.0336,  ...,  1.1702,  0.1436,  0.4704],\n",
    "#          [ 0.0355,  0.1407,  0.0450,  ...,  1.1279,  0.0273,  0.4527],\n",
    "#          ...,\n",
    "#          [-0.0236,  0.0494,  0.1736,  ..., -0.4440, -1.1006, -0.5862],\n",
    "#          [-0.0308,  0.0440,  0.1965,  ..., -0.6584, -1.1000, -0.5023],\n",
    "#          [ 0.0411,  0.1527, -0.0938,  ...,  0.5289,  0.0380,  0.5038]]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.3011e-01, -3.1431e-01,  1.6472e-01,  ...,  1.2347e-01,\n",
      "           1.3407e-01,  8.7543e-02],\n",
      "         [ 1.6650e-02, -1.4323e-01, -9.4386e-02,  ..., -2.1990e-02,\n",
      "           1.2575e-01, -3.5732e-02],\n",
      "         [ 1.9453e-01, -9.8574e-02,  1.7581e-01,  ..., -5.6061e-02,\n",
      "          -3.9454e-02, -1.2669e-01],\n",
      "         ...,\n",
      "         [-1.7987e-03,  1.6052e-03, -5.5103e-02,  ...,  1.3617e-02,\n",
      "          -7.1805e-03,  3.7552e-03],\n",
      "         [ 3.2105e-03,  1.5501e-03, -4.8944e-02,  ...,  2.0725e-02,\n",
      "          -1.1838e-02, -5.5683e-04],\n",
      "         [ 2.6610e-04,  3.0272e-03, -1.7086e-03,  ..., -4.6506e-03,\n",
      "          -2.3541e-03, -5.7855e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bicke\\AppData\\Local\\Temp\\ipykernel_75672\\3038415613.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  input = torch.load(\"test.pt\")\n"
     ]
    }
   ],
   "source": [
    "input = torch.load(\"test.pt\")\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "print(\"hi\")\n",
    "print(\"hi\")\n",
    "print(\"hi\")\n",
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3127, -0.2442, -0.4301,  ...,  0.0202,  0.0171, -0.1011],\n",
      "        [-0.1874, -0.1978,  0.1544,  ...,  0.1984,  0.0252, -0.0735],\n",
      "        [ 0.0980, -0.1098,  0.0538,  ..., -0.1482, -0.0184, -0.0024],\n",
      "        ...,\n",
      "        [-0.0120, -0.0162,  0.0143,  ...,  0.0235, -0.0008,  0.0063],\n",
      "        [ 0.0094,  0.0250, -0.0181,  ...,  0.0107,  0.0086,  0.0132],\n",
      "        [-0.0309,  0.0459, -0.0016,  ..., -0.0150,  0.0050, -0.0171]])\n",
      "tensor([[ 0.3127, -0.1874,  0.0980,  ..., -0.0120,  0.0094, -0.0309],\n",
      "        [-0.2442, -0.1978, -0.1098,  ..., -0.0162,  0.0250,  0.0459],\n",
      "        [-0.4301,  0.1544,  0.0538,  ...,  0.0143, -0.0181, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0202,  0.1984, -0.1482,  ...,  0.0235,  0.0107, -0.0150],\n",
      "        [ 0.0171,  0.0252, -0.0184,  ..., -0.0008,  0.0086,  0.0050],\n",
      "        [-0.1011, -0.0735, -0.0024,  ...,  0.0063,  0.0132, -0.0171]])\n"
     ]
    }
   ],
   "source": [
    "def get_weight(d, name):\n",
    "        \"\"\"Retrieve weights from the appropriate dictionary.\"\"\"\n",
    "        return d[name]\n",
    "print(get_weight(cdict, f\"transformer.transformer.layers.{0}.self_attn.out_proj.weight\"))\n",
    "print(get_weight(pdict, f\"transformer.h.{0}.attn.c_proj.weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2304, 768])\n"
     ]
    }
   ],
   "source": [
    "#already loaded in \n",
    "custom_model.load_state_dict(cdict)\n",
    "\n",
    "pdict2 = pret.state_dict()\n",
    "cdict2 = custom_model.state_dict()\n",
    "# print(pdict2[\"transformer.h.0.attn.c_attn.weight\"].shape)\n",
    "print(cdict2[\"transformer.transformer.layers.0.self_attn.in_proj_weight\"].shape)\n",
    "# if False:\n",
    "i = 0 \n",
    "layer_explicit_map = {\n",
    "        f\"transformer.transformer.layers.{i}.linear1.weight\" : f\"transformer.h.{i}.mlp.c_fc.weight\" ,\n",
    "        f\"transformer.transformer.layers.{i}.linear1.bias\" : f\"transformer.h.{i}.mlp.c_fc.bias\" ,\n",
    "        f\"transformer.transformer.layers.{i}.linear2.weight\" : f\"transformer.h.{i}.mlp.c_proj.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.linear2.bias\" : f\"transformer.h.{i}.mlp.c_proj.bias\" ,\n",
    "        f\"transformer.transformer.layers.{i}.norm1.weight\" : f\"transformer.h.{i}.ln_1.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.norm1.bias\" : f\"transformer.h.{i}.ln_1.bias\", \n",
    "        f\"transformer.transformer.layers.{i}.norm2.weight\" : f\"transformer.h.{i}.ln_2.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.norm2.bias\" : f\"transformer.h.{i}.ln_2.bias\", \n",
    "        f\"transformer.transformer.layers.{i}.self_attn.out_proj.weight\" : f\"transformer.h.{i}.attn.c_proj.weight\", \n",
    "        f\"transformer.transformer.layers.{i}.self_attn.out_proj.bias\" : f\"transformer.h.{i}.attn.c_proj.bias\",\n",
    "        f\"transformer.transformer.layers.{i}.self_attn.in_proj_weight\":  f\"transformer.h.{i}.attn.c_attn.weight\",\n",
    "        f\"transformer.transformer.layers.{i}.self_attn.in_proj_bias\" : f\"transformer.h.{i}.attn.c_attn.bias\"\n",
    "    }\n",
    "\n",
    "# for k,v in layer_explicit_map.items():\n",
    "#     print(k, \" : \", v)\n",
    "#     if (cdict2[k].ndim == 2):\n",
    "#         print(cdict2[k][0:2, 0:2], \"\\n\",pdict2[v][0:2, 0:2])\n",
    "#     else:\n",
    "#         print(cdict2[k][0:2], \"\\n\",pdict2[v][0:2])\n",
    "#     print(\"----\")\n",
    "\n",
    "from bpe import BPETokenizer\n",
    "\n",
    "tokenizer = BPETokenizer()\n",
    "\n",
    "x = tokenizer(\"Once upon a time\")\n",
    "y = custom_model.forward_ppo_with_tokens(x, torch.zeros_like(x),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.topk(y[0][:,-1,:], k = 5, dim=-1).indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' exha loophsenal�士ortium'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length >\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "output\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "output\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
      "\n",
      "if outputs.length > 0 then\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "else\n",
      "\n",
      "outputs.push(dim)\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = custom_model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def generate(prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward_ppo_with_tokens(input_ids, torch.zeros_like(input_ids),0)[0][:,-1,:]\n",
    "            \n",
    "        next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\n",
    "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "        print(tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "        if next_token_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "        \n",
    "generate(\"next_token_id = outputs.argmax(dim=-1).unsqueeze(-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minput_ids\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_ids' is not defined"
     ]
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['transformer.dual_positional_encoding.learned_positional_encoding.weight', 'transformer.dual_positional_encoding.position_in_thought_encoding.weight', 'transformer.transformer.layers.0.self_attn.in_proj_weight', 'transformer.transformer.layers.0.self_attn.in_proj_bias', 'transformer.transformer.layers.0.self_attn.out_proj.weight', 'transformer.transformer.layers.0.self_attn.out_proj.bias', 'transformer.transformer.layers.0.linear1.weight', 'transformer.transformer.layers.0.linear1.bias', 'transformer.transformer.layers.0.linear2.weight', 'transformer.transformer.layers.0.linear2.bias', 'transformer.transformer.layers.0.norm1.weight', 'transformer.transformer.layers.0.norm1.bias', 'transformer.transformer.layers.0.norm2.weight', 'transformer.transformer.layers.0.norm2.bias', 'transformer.transformer.layers.1.self_attn.in_proj_weight', 'transformer.transformer.layers.1.self_attn.in_proj_bias', 'transformer.transformer.layers.1.self_attn.out_proj.weight', 'transformer.transformer.layers.1.self_attn.out_proj.bias', 'transformer.transformer.layers.1.linear1.weight', 'transformer.transformer.layers.1.linear1.bias', 'transformer.transformer.layers.1.linear2.weight', 'transformer.transformer.layers.1.linear2.bias', 'transformer.transformer.layers.1.norm1.weight', 'transformer.transformer.layers.1.norm1.bias', 'transformer.transformer.layers.1.norm2.weight', 'transformer.transformer.layers.1.norm2.bias', 'transformer.transformer.layers.2.self_attn.in_proj_weight', 'transformer.transformer.layers.2.self_attn.in_proj_bias', 'transformer.transformer.layers.2.self_attn.out_proj.weight', 'transformer.transformer.layers.2.self_attn.out_proj.bias', 'transformer.transformer.layers.2.linear1.weight', 'transformer.transformer.layers.2.linear1.bias', 'transformer.transformer.layers.2.linear2.weight', 'transformer.transformer.layers.2.linear2.bias', 'transformer.transformer.layers.2.norm1.weight', 'transformer.transformer.layers.2.norm1.bias', 'transformer.transformer.layers.2.norm2.weight', 'transformer.transformer.layers.2.norm2.bias', 'transformer.transformer.layers.3.self_attn.in_proj_weight', 'transformer.transformer.layers.3.self_attn.in_proj_bias', 'transformer.transformer.layers.3.self_attn.out_proj.weight', 'transformer.transformer.layers.3.self_attn.out_proj.bias', 'transformer.transformer.layers.3.linear1.weight', 'transformer.transformer.layers.3.linear1.bias', 'transformer.transformer.layers.3.linear2.weight', 'transformer.transformer.layers.3.linear2.bias', 'transformer.transformer.layers.3.norm1.weight', 'transformer.transformer.layers.3.norm1.bias', 'transformer.transformer.layers.3.norm2.weight', 'transformer.transformer.layers.3.norm2.bias', 'transformer.transformer.layers.4.self_attn.in_proj_weight', 'transformer.transformer.layers.4.self_attn.in_proj_bias', 'transformer.transformer.layers.4.self_attn.out_proj.weight', 'transformer.transformer.layers.4.self_attn.out_proj.bias', 'transformer.transformer.layers.4.linear1.weight', 'transformer.transformer.layers.4.linear1.bias', 'transformer.transformer.layers.4.linear2.weight', 'transformer.transformer.layers.4.linear2.bias', 'transformer.transformer.layers.4.norm1.weight', 'transformer.transformer.layers.4.norm1.bias', 'transformer.transformer.layers.4.norm2.weight', 'transformer.transformer.layers.4.norm2.bias', 'transformer.transformer.layers.5.self_attn.in_proj_weight', 'transformer.transformer.layers.5.self_attn.in_proj_bias', 'transformer.transformer.layers.5.self_attn.out_proj.weight', 'transformer.transformer.layers.5.self_attn.out_proj.bias', 'transformer.transformer.layers.5.linear1.weight', 'transformer.transformer.layers.5.linear1.bias', 'transformer.transformer.layers.5.linear2.weight', 'transformer.transformer.layers.5.linear2.bias', 'transformer.transformer.layers.5.norm1.weight', 'transformer.transformer.layers.5.norm1.bias', 'transformer.transformer.layers.5.norm2.weight', 'transformer.transformer.layers.5.norm2.bias', 'transformer.transformer.layers.6.self_attn.in_proj_weight', 'transformer.transformer.layers.6.self_attn.in_proj_bias', 'transformer.transformer.layers.6.self_attn.out_proj.weight', 'transformer.transformer.layers.6.self_attn.out_proj.bias', 'transformer.transformer.layers.6.linear1.weight', 'transformer.transformer.layers.6.linear1.bias', 'transformer.transformer.layers.6.linear2.weight', 'transformer.transformer.layers.6.linear2.bias', 'transformer.transformer.layers.6.norm1.weight', 'transformer.transformer.layers.6.norm1.bias', 'transformer.transformer.layers.6.norm2.weight', 'transformer.transformer.layers.6.norm2.bias', 'transformer.transformer.layers.7.self_attn.in_proj_weight', 'transformer.transformer.layers.7.self_attn.in_proj_bias', 'transformer.transformer.layers.7.self_attn.out_proj.weight', 'transformer.transformer.layers.7.self_attn.out_proj.bias', 'transformer.transformer.layers.7.linear1.weight', 'transformer.transformer.layers.7.linear1.bias', 'transformer.transformer.layers.7.linear2.weight', 'transformer.transformer.layers.7.linear2.bias', 'transformer.transformer.layers.7.norm1.weight', 'transformer.transformer.layers.7.norm1.bias', 'transformer.transformer.layers.7.norm2.weight', 'transformer.transformer.layers.7.norm2.bias', 'transformer.transformer.layers.8.self_attn.in_proj_weight', 'transformer.transformer.layers.8.self_attn.in_proj_bias', 'transformer.transformer.layers.8.self_attn.out_proj.weight', 'transformer.transformer.layers.8.self_attn.out_proj.bias', 'transformer.transformer.layers.8.linear1.weight', 'transformer.transformer.layers.8.linear1.bias', 'transformer.transformer.layers.8.linear2.weight', 'transformer.transformer.layers.8.linear2.bias', 'transformer.transformer.layers.8.norm1.weight', 'transformer.transformer.layers.8.norm1.bias', 'transformer.transformer.layers.8.norm2.weight', 'transformer.transformer.layers.8.norm2.bias', 'transformer.transformer.layers.9.self_attn.in_proj_weight', 'transformer.transformer.layers.9.self_attn.in_proj_bias', 'transformer.transformer.layers.9.self_attn.out_proj.weight', 'transformer.transformer.layers.9.self_attn.out_proj.bias', 'transformer.transformer.layers.9.linear1.weight', 'transformer.transformer.layers.9.linear1.bias', 'transformer.transformer.layers.9.linear2.weight', 'transformer.transformer.layers.9.linear2.bias', 'transformer.transformer.layers.9.norm1.weight', 'transformer.transformer.layers.9.norm1.bias', 'transformer.transformer.layers.9.norm2.weight', 'transformer.transformer.layers.9.norm2.bias', 'transformer.transformer.layers.10.self_attn.in_proj_weight', 'transformer.transformer.layers.10.self_attn.in_proj_bias', 'transformer.transformer.layers.10.self_attn.out_proj.weight', 'transformer.transformer.layers.10.self_attn.out_proj.bias', 'transformer.transformer.layers.10.linear1.weight', 'transformer.transformer.layers.10.linear1.bias', 'transformer.transformer.layers.10.linear2.weight', 'transformer.transformer.layers.10.linear2.bias', 'transformer.transformer.layers.10.norm1.weight', 'transformer.transformer.layers.10.norm1.bias', 'transformer.transformer.layers.10.norm2.weight', 'transformer.transformer.layers.10.norm2.bias', 'transformer.transformer.layers.11.self_attn.in_proj_weight', 'transformer.transformer.layers.11.self_attn.in_proj_bias', 'transformer.transformer.layers.11.self_attn.out_proj.weight', 'transformer.transformer.layers.11.self_attn.out_proj.bias', 'transformer.transformer.layers.11.linear1.weight', 'transformer.transformer.layers.11.linear1.bias', 'transformer.transformer.layers.11.linear2.weight', 'transformer.transformer.layers.11.linear2.bias', 'transformer.transformer.layers.11.norm1.weight', 'transformer.transformer.layers.11.norm1.bias', 'transformer.transformer.layers.11.norm2.weight', 'transformer.transformer.layers.11.norm2.bias', 'transformer.transformer.norm.weight', 'transformer.transformer.norm.bias', 'policy_feedforward.weight', 'value_feedforward.0.weight', 'value_feedforward.0.bias', 'value_feedforward.2.weight', 'value_feedforward.2.bias', 'token_embedding.weight'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdict['transformer.wte.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_ppo_with_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m t\u001b[38;5;241m.\u001b[39mdecode(x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\bicke\\Documents\\GitHub\\Thoughtsformer\\one_step_thoughtsformer.py:322\u001b[0m, in \u001b[0;36mThoughtsFormer.forward_ppo_with_tokens\u001b[1;34m(self, tokens, padding_mask, n_thoughts_taken)\u001b[0m\n\u001b[0;32m    320\u001b[0m   padding_mask \u001b[38;5;241m=\u001b[39m padding_mask\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Embed the tokens\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m state_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Call the existing forward_ppo method\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_ppo(state_embeddings, padding_mask, n_thoughts_taken)\n",
      "File \u001b[1;32mc:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "predictions = custom_model.forward_ppo_with_tokens(tokens, torch.zeros_like(tokens),0)[0]\n",
    "x = predictions.argmax(dim=-1)\n",
    "t.decode(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.bool().dtype == torch.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attention heads: 12\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bicke\\anaconda3\\envs\\megatron\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:720: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The quick brown fox jumps over the lazy\n",
      "Top 5 predicted next tokens:\n",
      "1. ' looph' (score: 14.0095)\n",
      "2. ' exha' (score: 12.0068)\n",
      "3. '�士' (score: 11.4057)\n",
      "4. ' tremend' (score: 9.3803)\n",
      "5. ' millenn' (score: 9.2363)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "def predict_next_token(model: ThoughtsFormer, tokenizer, sentence, device):\n",
    "    # Tokenize the input sentence\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Generate attention mask\n",
    "    attention_mask = torch.zeros_like(input_ids).to(device).bool()\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward_ppo_with_tokens(input_ids, attention_mask, 0)\n",
    "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "    \n",
    "    # Get the predictions for the last token\n",
    "    next_token_logits = logits[0, -1, :]\n",
    "    \n",
    "    # Get the top 5 candidates\n",
    "    top_5_tokens = torch.topk(next_token_logits, 5, dim=-1)\n",
    "    \n",
    "    return top_5_tokens.indices, top_5_tokens.values\n",
    "\n",
    "# Set up the model and tokenizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = ThoughtsFormer(vocab_size=50257, d_embed=768, dim_feed_forward=768 * 4, n_head=12, max_context_length=1024, thought_length=0, sinusoidal_position_encoding=False).to(device)\n",
    "\n",
    "# Load your trained weights\n",
    "model = custom_model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Test sentence\n",
    "test_sentence = \"The quick brown fox jumps over the lazy\"\n",
    "\n",
    "# Predict next token\n",
    "top_indices, top_scores = predict_next_token(model, tokenizer, test_sentence, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"Input: {test_sentence}\")\n",
    "print(\"Top 5 predicted next tokens:\")\n",
    "for i, (index, score) in enumerate(zip(top_indices, top_scores), 1):\n",
    "    token = tokenizer.decode([index])\n",
    "    print(f\"{i}. '{token}' (score: {score.item():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method 2: Save only the state dictionary (recommended)\n",
    "torch.save(custom_model.state_dict(), 'gpt2_starting_thoughtsformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megatron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
