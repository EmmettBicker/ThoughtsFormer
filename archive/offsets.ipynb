{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def batched_simt_reshape_with_offset(x: torch.Tensor, offset: int, row_length: int, pad_value: int = 0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reshapes a batched 3D tensor into a new 4D tensor based on an offset value,\n",
    "    grouping elements and padding each row to the specified length while preserving the embedding dimension.\n",
    "    This version is optimized for SIMT architectures and handles batched inputs with embeddings.\n",
    "\n",
    "    Args:\n",
    "    x (torch.Tensor): Input batched 3D tensor of shape (batch_size, sequence_length, d_embed)\n",
    "    offset (int): Number of elements to group before padding\n",
    "    row_length (int): Desired length of each row in the output\n",
    "    pad_value (int): Value to use for padding (default: 0)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Reshaped and padded batched 4D tensor\n",
    "    \"\"\"\n",
    "    batch_size, input_length, d_embed = x.shape\n",
    "    num_rows = math.ceil(input_length / row_length)\n",
    "    \n",
    "    # Create output tensor filled with pad_value\n",
    "    output = torch.full((batch_size, num_rows, row_length, d_embed), pad_value, dtype=x.dtype, device=x.device)\n",
    "    \n",
    "    # Create a mask for non-pad values (assuming pad_value is applied across the entire embedding)\n",
    "    mask = (x != pad_value).any(dim=-1)\n",
    "    \n",
    "    # Get the indices of non-pad values\n",
    "    batch_indices, seq_indices = torch.where(mask)\n",
    "    \n",
    "    # Calculate row and column indices for the output\n",
    "    row_indices = (seq_indices // offset) % num_rows\n",
    "    col_indices = seq_indices % offset\n",
    "    \n",
    "    # Filter out column indices that are out of bounds\n",
    "    valid_indices = col_indices < row_length\n",
    "    batch_indices = batch_indices[valid_indices]\n",
    "    row_indices = row_indices[valid_indices]\n",
    "    col_indices = col_indices[valid_indices]\n",
    "    seq_indices = seq_indices[valid_indices]\n",
    "    \n",
    "    # Use advanced indexing to fill the output tensor\n",
    "    output[batch_indices, row_indices, col_indices] = x[batch_indices, seq_indices]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 4, 3])\n",
      "Result for x1:\n",
      "tensor([[[ 7,  8,  9],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0]]])\n",
      "Result for x2:\n",
      "tensor([[[1, 2, 3],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]]])\n",
      "Result for x3:\n",
      "tensor([[[13, 14, 15],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0]],\n",
      "\n",
      "        [[16, 17, 18],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0],\n",
      "         [ 0,  0,  0]]])\n",
      "Result for x4:\n",
      "tensor([[[7, 8, 9],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage with batched inputs including embedding dimension\n",
    "d_embed = 3\n",
    "x1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "x2 = torch.tensor([[1, 2, 3], [4, 5, 6], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "x3 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15], [16, 17, 18], [0, 0, 0], [0, 0, 0]])\n",
    "x4 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
    "\n",
    "# Create a batched input\n",
    "batched_input = torch.stack([x1, x2, x3, x4])\n",
    "\n",
    "row_length = 4\n",
    "\n",
    "result = batched_simt_reshape_with_offset(batched_input, offset=1, row_length=row_length)\n",
    "\n",
    "print(result.shape)\n",
    "\n",
    "# You can access individual results like this:\n",
    "print(\"Result for x1:\")\n",
    "print(result[0])\n",
    "print(\"Result for x2:\")\n",
    "print(result[1])\n",
    "print(\"Result for x3:\")\n",
    "print(result[2])\n",
    "print(\"Result for x4:\")\n",
    "print(result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megatron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
